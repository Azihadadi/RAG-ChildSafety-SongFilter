{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMweohCRjA1D"
      },
      "outputs": [],
      "source": [
        "!pip install --user numpy\n",
        "!pip install --user torch==2.2.0\n",
        "!pip install --user sacremoses==0.1.1\n",
        "!pip install --user torchtext\n",
        "!pip install --user transformers==4.40.2\n",
        "!pip install --user matplotlib==3.8.4\n",
        "!pip install --user sentencepiece==0.2.0\n",
        "!pip install --user scikit-learn==1.4.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# You can also use this section to suppress warnings generated by your code:\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "0uDE0b9DkQXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tsne_plot(data, plot):\n",
        "    # Apply t-SNE to reduce to 3D\n",
        "    tsne = TSNE(n_components=3, random_state=42, perplexity=min(50, data.shape[0] - 1))  # Using 50 or less based on data size\n",
        "    data_3d = tsne.fit_transform(data)\n",
        "\n",
        "    # Plotting\n",
        "    fig = plt.figure(figsize=(10, 7))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    # Assign colors for each point based on its index\n",
        "    colors = plt.cm.rainbow(np.linspace(0, 1, len(data_3d)))\n",
        "    for idx, point in zip(range(len(data_3d)), data_3d):\n",
        "        ax.scatter(point[0], point[1], point[2], color=colors[idx], label=f'{plot} {idx+1}')\n",
        "\n",
        "    # Adding labels and titles\n",
        "    ax.set_xlabel('TSNE Component 1')\n",
        "    ax.set_ylabel('TSNE Component 2')\n",
        "    ax.set_zlabel('TSNE Component 3')\n",
        "    plt.title('3D t-SNE Visualization of '+ plot +' Embeddings')\n",
        "    plt.legend(title=plot +' Index', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "rGXVTjonkc9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "LaZGB4u4kqLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input text to get embeddings for\n",
        "input_text = [(\"This is an example sentence for BERT embeddings.\", \"How do you like it \"),(\"There are other models\")]"
      ],
      "metadata": {
        "id": "BKZPxiJtkxoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DEVICE"
      ],
      "metadata": {
        "id": "57epfLl_lprH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "pyDWXb_Jl1fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model.to(DEVICE)"
      ],
      "metadata": {
        "id": "HYH_7feol3Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def aggregate_embeddings(input_ids, attention_masks, bert_model=bert_model):\n",
        "    \"\"\"\n",
        "    Converts token indices and masks to word embeddings, filters out zero-padded embeddings,\n",
        "    and aggregates them by computing the mean embedding for each input sequence.\n",
        "\n",
        "    \"\"\"\n",
        "    mean_embeddings = []\n",
        "    # Process each sequence in the batch\n",
        "    print('number of inputs',len(input_ids))\n",
        "    for input_id, mask in tqdm(zip(input_ids, attention_masks)):\n",
        "        input_ids_tensor = torch.tensor([input_id]).to(DEVICE)\n",
        "        mask_tensor = torch.tensor([mask]).to(DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Obtain the word embeddings from the BERT model\n",
        "            word_embeddings = bert_model(input_ids_tensor, attention_mask=mask_tensor)[0].squeeze(0)\n",
        "\n",
        "            # Filter out the embeddings at positions where the mask is zero\n",
        "            valid_embeddings_mask=mask_tensor[0] != 0\n",
        "            valid_embeddings = word_embeddings[valid_embeddings_mask,:]\n",
        "            # Compute the mean of the filtered embeddings\n",
        "            mean_embedding = valid_embeddings.mean(dim=0)\n",
        "            mean_embeddings.append(mean_embedding.unsqueeze(0))\n",
        "\n",
        "    # Concatenate the mean embeddings from all sequences in the batch\n",
        "    aggregated_mean_embeddings = torch.cat(mean_embeddings)\n",
        "    return aggregated_mean_embeddings"
      ],
      "metadata": {
        "id": "uhY0-vROmSAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_emb(list_of_text,max_input=512):\n",
        "    data_token_index  = tokenizer.batch_encode_plus(list_of_text, add_special_tokens=True,padding=True,truncation=True,max_length=max_input)\n",
        "    question_embeddings=aggregate_embeddings(data_token_index['input_ids'], data_token_index['attention_mask'])\n",
        "    return question_embeddings"
      ],
      "metadata": {
        "id": "DMlh6Bs3nDAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def process_song(song):\n",
        "    # Remove line breaks from the song\n",
        "    song_new = re.sub(r'[\\n]', ' ', song)\n",
        "\n",
        "    # Remove single quotes from the song\n",
        "    song_new = [song_new.replace(\"\\'\", \"\")]\n",
        "\n",
        "    return song_new"
      ],
      "metadata": {
        "id": "tmRkMtt8nXHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "song_questions = [\n",
        "    \"Does this song contain any violent themes, such as references to guns, killing, or physical aggression? Example: Does the song describe or promote physical violence, like fighting or shootings?\",\n",
        "    \"Are there any explicit lyrics or bad words used in this song that might be considered offensive or inappropriate? Example: Does the song use language commonly recognized as profanity or derogatory terms?\",\n",
        "    \"Is the overall content of this song suitable for children, considering its themes, language, and messages? Example: Are there elements in the song that could be deemed too mature or unsuitable for young listeners?\",\n",
        "    \"Does this song explicitly mention weapons, such as guns, knives, or other similar items? Example: Are specific types of weapons described or glorified in the lyrics?\",\n",
        "    \"Are the messages conveyed in this song positive and uplifting for children? Example: Does the song promote values like kindness, friendship, and positivity?\",\n",
        "    \"Does this song include any sexual content, references to sexual behavior, or suggestive language? Example: Are there lyrics that explicitly or implicitly discuss sexual themes or experiences?\",\n",
        "    \"Does this song offer any educational value, such as teaching the alphabet, basic math, or other learning content? Example: Are there educational segments in the song that could help children learn fundamental skills like the ABCs or counting?\",\n",
        "    \"Does this song promote emotional resilience and social skills among children? Example: Does the song include themes of overcoming challenges or building friendships?\"\n",
        "]"
      ],
      "metadata": {
        "id": "aD8hYipnndjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_questions=street=text_to_emb(song_questions)"
      ],
      "metadata": {
        "id": "LDLXxxLynlyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tsne_plot(embeddings_questions, \"Question\")"
      ],
      "metadata": {
        "id": "ARO2J2GWnotI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yes_responses = [\n",
        "    \"Yes, this song contains violent themes, including references to guns, killing, or physical aggression, and is not suitable for children.\",\n",
        "    \"Yes, this song includes explicit lyrics or bad words that might be considered offensive or inappropriate for young audiences.\",\n",
        "    \"No, the overall content of this song is not suitable for children as it includes themes, language, and messages that are too mature or unsuitable for young listeners.\",\n",
        "    \"Yes, this song explicitly mentions weapons, such as guns and knives, which could be disturbing or inappropriate for childrenâ€™s entertainment.\",\n",
        "    \"Yes, the messages conveyed in this song are positive and uplifting, promoting values like kindness, friendship, and positivity, beneficial for children.\",\n",
        "    \"Yes, this song includes sexual content and references to sexual behavior or suggestive language, which are inappropriate for a child-friendly environment.\",\n",
        "    \"Yes, this song offers significant educational value, including segments that teach the alphabet, basic math, and other learning content, making it both fun and educational for children.\",\n",
        "    \"Yes, this song promotes emotional resilience and social skills, incorporating themes about overcoming challenges and building friendships, which are essential for children's development.\"\n",
        "]"
      ],
      "metadata": {
        "id": "9EHrBtYMnusB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_responses = text_to_emb(yes_responses)"
      ],
      "metadata": {
        "id": "pSX6SJKQn0Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tsne_plot(embeddings_responses, \"Response\")"
      ],
      "metadata": {
        "id": "HWA_4aaYn2bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sesame_street = \"\"\"\n",
        "Sunny day\n",
        "Sweepin' the clouds away\n",
        "On my way to where the air is sweet\n",
        "Can you tell me how to get\n",
        "How to get to Sesame Street?\n",
        "\n",
        "Come and play\n",
        "Everything's A-okay\n",
        "Friendly neighbors there\n",
        "That's where we meet\n",
        "Can you tell me how to get\n",
        "How to get to Sesame Street?\n",
        "\n",
        "It's a magic carpet ride\n",
        "Every door will open wide\n",
        "To happy people like you\n",
        "Happy people like\n",
        "What a beautiful\n",
        "\n",
        "Sunny day\n",
        "Sweepin' the clouds away\n",
        "On my way to where the air is sweet\n",
        "Can you tell me how to get\n",
        "How to get to Sesame Street?\n",
        "How to get to Sesame Street?\n",
        "How to get to Sesame Street?\n",
        "How to get to Sesame Street?\n",
        "How to get to Sesame Street?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "8JwztMpvtfNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "song_sesame_street= process_song(sesame_street)\n",
        "embeddings_sesame_street=text_to_emb(song_sesame_street)"
      ],
      "metadata": {
        "id": "hdUOtJ7Foe7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_shoe_lyrics=\"\"\"Barney is a dinosaur from our imagination\n",
        "And when he's tall\n",
        "He's what we call a dinosaur sensation\n",
        "Barney's friends are big and small\n",
        "They come from lots of places\n",
        "After school they meet to play\n",
        "And sing with happy faces\n",
        "Barney shows us lots of things\n",
        "Like how to play pretend\n",
        "ABC's, and 123's\n",
        "And how to be a friend\n",
        "Barney comes to play with us\n",
        "Whenever we may need him\n",
        "Barney can be your friend too\n",
        "If you just make-believe him!\"\"\""
      ],
      "metadata": {
        "id": "QPjPB2FBtnnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_shoe_lyrics= process_song(my_shoe_lyrics)\n",
        "embeddings_my_shoe=text_to_emb(my_shoe_lyrics)"
      ],
      "metadata": {
        "id": "r9kL8RPktpZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "songs = [song_sesame_street, my_shoe_lyrics]\n",
        "embeddings = [text_to_emb(song) for song in songs]\n",
        "all_embeddings = np.vstack(embeddings)"
      ],
      "metadata": {
        "id": "N_sX9lsxtrjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tsne_plot(all_embeddings, \"Song\")"
      ],
      "metadata": {
        "id": "gF7P612StuXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dot Product Similarity"
      ],
      "metadata": {
        "id": "e5uQ9Xybxow6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RAG_QA(embeddings_questions, embeddings, n_responses=3):\n",
        "    # Calculate the dot product between the question embeddings and the provided embeddings (transpose of the second matrix for proper alignment).\n",
        "    dot_product = embeddings_questions @ embeddings.T\n",
        "\n",
        "    # Reshape the dot product results to a 1D tensor for easier processing.\n",
        "    dot_product = dot_product.reshape(-1)\n",
        "\n",
        "    # Sort the indices of the dot product results in descending order (setting descending to False should be True for typical similarity tasks).\n",
        "    sorted_indices = torch.argsort(dot_product, descending=True)\n",
        "\n",
        "    # Convert sorted indices to a list for easier iteration.\n",
        "    sorted_indices = sorted_indices.tolist()\n",
        "\n",
        "    # Print the top 'n_responses' responses from the sorted list, which correspond to the highest dot product values.\n",
        "    for index in sorted_indices[:n_responses]:\n",
        "        print(yes_responses[index])"
      ],
      "metadata": {
        "id": "OjmxloZbudjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RAG_QA(embeddings_questions, embeddings_sesame_street)"
      ],
      "metadata": {
        "id": "r08BZn2VuxsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RAG_QA(embeddings_questions, embeddings_compton)"
      ],
      "metadata": {
        "id": "83hOQ3MKuzLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RAG_QA(embeddings_questions, embeddings_my_shoe)"
      ],
      "metadata": {
        "id": "lk9ROkBmu09-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cosine Similarity"
      ],
      "metadata": {
        "id": "MK76FyJRxkYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RAG_QA_cosine(embeddings, n_responses=3):\n",
        "    # Calculate the magnitudes (norms) of the question and response embeddings\n",
        "    question_norms = torch.norm(embeddings_questions, dim=1, keepdim=True)\n",
        "    response_norms = torch.norm(embeddings, dim=1, keepdim=True)\n",
        "\n",
        "    # Calculate the dot product between the question embeddings and the provided embeddings (transpose of the second matrix for proper alignment)\n",
        "    dot_product = torch.mm(embeddings_questions, embeddings.T)\n",
        "\n",
        "    # Calculate cosine similarity by dividing the dot product by the product of the magnitudes\n",
        "    cosine_similarity = dot_product / (question_norms * response_norms.T)\n",
        "\n",
        "    # Flatten the cosine similarity tensor to a 1D tensor for easier processing\n",
        "    cosine_similarity = cosine_similarity.reshape(-1)\n",
        "\n",
        "    # Sort the indices of the cosine similarity results in descending order to get the indices with the highest similarity\n",
        "    sorted_indices = torch.argsort(cosine_similarity, descending=True)\n",
        "\n",
        "    # Convert sorted indices to a list for easier iteration\n",
        "    sorted_indices = sorted_indices.tolist()\n",
        "\n",
        "    # Print the top 'n_responses' responses from the sorted list, which correspond to the highest cosine similarity values\n",
        "    for index in sorted_indices[:n_responses]:\n",
        "        print(yes_responses[index])  # Ensure 'responses' is defined and accessible in your scope"
      ],
      "metadata": {
        "id": "iDPEtTXrxZjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RAG_QA_cosine(embeddings_my_shoe, n_responses=3)"
      ],
      "metadata": {
        "id": "xzkA3H-Ixbea"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
